#!/usr/bin/env python
#coding:utf-8



"""
1、SLRM（Sparse Logistic Regression Model）
1) 本质上SLRM是对原始的SLIM模型做了一些改进，将其变换成一个Sparse LR Model，简化了整个计算过程。
2) SLRM的贡献点：
	- 利用SLIM的优点，基于用户过去的行为来预测用户未来的行为，整个样本集都是关于用户过去的行为，不需要对行为进行特征抽取，即不需要耗费精力做特征工程；
	- 将SLIM转化为LR的形式，简化了整个求解过程。
	- in one word, 效果好、没有繁琐的特征工程、可以落地。

2、SLRM是基于SLIM 和 GL-SLIM发展而来：
1) 资料：https://blog.csdn.net/weixin_39064571/article/details/78835939
2) SLIM总结：
	- SLIM 既考虑到了利用用户物品行为之间的相似度来缩短训练时间（neighborhood-based），又利用学习训练过程提升了结果的精度（model-based）；
	- 由于矩阵 A 很稀疏（一个用户只会对很小一部分物品有过行为，注意在这个算法里，矩阵缺失值填0），学习到的 W 也很稀疏：
	（1）是L1正则化会产生稀疏解；
	（2）是特征选择的过程本身就将用户行为相似度低的物品们的权重置零了；
	- SLIM的问题：
	（1）SLIM 是对全局信息进行统一的学习过程，
	（2）但是用户之间是可以根据用户行为聚类的，各类里独有的行为，用一个 global 的模型恐怕不能完整地描述出来。
3) GL-SLIM应运而生。
	- 原理：https://www-users.cs.umn.edu/~chri2951/recsy368-christakopoulouA.pdf
	- GL-SLIM的公式看似很复杂，其实很简单：
	（1）paper中的公式（3）和公式（4）中带有难懂符号的那一坨其实是等价的。
	（2）为什么等价？因为一个user只能属于一个类，当它属于pu类时，那么user在其它R^{!pu}上的值为0。
	（3）g_u是每个用户独有的权重系数，代表该用户更倾向于全局模型还是局部模型，该系数位于【0,1】区间内，它会有个初始值，但会在迭代学习中发生改变。
	（4）GL-SLIM需要求解的变量有三个：
		- 物品之间的全局系数矩阵S_i
		- 物品之间在各个用户群的局部相似矩阵S_i^pu；
		- model中global的权重g_u；
	（5）求解trick:
		- 如果固定g的取值，那么整个公式就会变一个求解系数矩阵的带约束的最优化问题，通过迭代就可以顺利的求出S_i和S_i^pu；
		- 在S_i和S_i^pu都固定的前提下，整个公式又变成了g_u的最优化问题，so easy!
		- 通过分别固定g_u和S_i和S_i^pu，嵌套两轮迭代就可以得出最优解；
	- GL-SLIM会对user进行聚类划分，使用的聚类算法，作者并没详述，只是说用了CLUTO软件包，已经证明使用聚类比随机分配的效果好。
	- **GL-SLIM并不依赖CLUTO的聚类效果，因为GLSLIM 算法本身还会对聚类结果进行调整。
	（1）在while循环里，对每个用户，会把他分到训练误差最小的那一类去。只要当聚类的结果改变超过 1% 时，会一直迭代下去。
	（2）GL-SLIM 的结果要优于 SLIM，但是这个准确度的提升，是建立在更多次的迭代和更多的基模型的基础上的。
	- 两种变体：
	（1）LSLIM 与 GLSLIM 相比，没有去训练全局模型，只训练了各用户群的局部模型。效果会比GLSLIM稍差一些，毕竟训练过程缩短，没有训练全局模型，捕捉不到全局信息。
	（2）GLSLIMr0 与GLSLIM 相比，相信聚类算法的结果，不在每次迭代中对用户所在的用户群进行更改，当某次迭代和上一次的训练误差相比变化不大时，停止训练。
4) 评价指标
	- 基于precision、recall的评价指标有一个缺点是：推荐列表中的每一个项目都被认为对用户是同样感兴趣的，这明显不符合客观情况。
	- 针对这个问题，选用HR和ARHR来作为评价标准更为合适。

5) ****待填的坑：
	- HR和ARHR评价指标的原理和适用场景。
	- AUC的计算原理，它是否具有precision、recall一样的劣势。（个人感觉大概率是）
	- SLRM survey 最后的几个图是什么意思？
	- SWING I2I 是什么？
	- 填完后可以开始撸深度学习了。Oh Year~~ 有些小鸡冻啊~
"""


